{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Image Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access image directories\n",
    "train_dir = 'C:/Users/GOKAY/Desktop/imagenette4/train/'\n",
    "val_dir = 'C:/Users/GOKAY/Desktop/imagenette4/val/'\n",
    "test_dir = 'C:/Users/GOKAY/Desktop/imagenette4/test/'\n",
    "\n",
    "train = []\n",
    "for filename in os.listdir(train_dir):\n",
    "    if filename.endswith(\".JPEG\"):\n",
    "        img = image.load_img(train_dir+filename)\n",
    "        train.append(image.img_to_array(img))\n",
    "train = np.array(train)\n",
    "\n",
    "val = []\n",
    "for filename in os.listdir(val_dir):\n",
    "    if filename.endswith(\".JPEG\"):\n",
    "        img = image.load_img(val_dir+filename)\n",
    "        val.append(image.img_to_array(img))\n",
    "val = np.array(val)\n",
    "\n",
    "test = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith(\".JPEG\"):\n",
    "        img = image.load_img(test_dir+filename)\n",
    "        test.append(image.img_to_array(img))\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train\", train.shape)\n",
    "print(\"val\", val.shape)\n",
    "print(\"test\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the autoencoder with latent space 80x80\n",
    "def first_model():\n",
    "    #encoder\n",
    "    input_layer = Input(shape=(160,160,3), name='INPUT')\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "\n",
    "    latent_layer = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    #decoder\n",
    "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(latent_layer)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    output_layer = Conv2D(3, (3, 3), padding='same', name=\"OUTPUT\")(x)\n",
    "    \n",
    "    #creating the model\n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.0015), loss='mse')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "#the autoencoder with latent space 40x40\n",
    "def second_model():\n",
    "    #encoder\n",
    "    input_layer = Input(shape=(160,160,3), name='INPUT')\n",
    "    x = Conv2D(32, (3, 3), activation='leaky_relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='leaky_relu', padding='same')(x)\n",
    "\n",
    "    latent_layer = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    #decoder\n",
    "    x = Conv2DTranspose(64, (3, 3), activation='leaky_relu', padding='same')(latent_layer)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(32, (3, 3), activation='leaky_relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    output_layer = Conv2D(3, (3, 3), padding='same', name=\"OUTPUT\")(x)\n",
    "\n",
    "    #creating the model\n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.0017), loss='mse')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "#the autoencoder with 20x20 latent space\n",
    "def third_model():\n",
    "    #encoder\n",
    "    input_layer = Input(shape=(160,160,3), name='INPUT')\n",
    "    x = Conv2D(32, (3, 3), activation='leaky_relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='leaky_relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='leaky_relu', padding='same')(x)\n",
    "\n",
    "    latent_layer = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    #decoder\n",
    "    x = Conv2DTranspose(128, (3, 3), activation='leaky_relu', padding='same')(latent_layer)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), activation='leaky_relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2DTranspose(32, (3, 3), activation='leaky_relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    output_layer = Conv2D(3, (3, 3), padding='same', name=\"OUTPUT\")(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.0021), loss='mse')\n",
    "\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(model_no):\n",
    "    #checkpoint to save the best result\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'ae{model_no}.keras',          \n",
    "        monitor='val_loss',       \n",
    "        save_best_only=True,      \n",
    "        mode='min',               \n",
    "        verbose=1                 \n",
    "    )\n",
    "\n",
    "    #Setting up early stopping to stop the training when no improvment is achieved and receiving the best results(weights)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,                \n",
    "        verbose=1,                 \n",
    "        mode='min',               \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return checkpoint, early_stopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Each Model and Training Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = first_model()\n",
    "ae1.fit(train, train, epochs=100, batch_size=32, validation_data=(val, val), callbacks=check(1), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae2 = second_model()\n",
    "ae2.fit(train, train, epochs=100, batch_size=32, validation_data=(val, val),callbacks=check(2), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae3 = third_model()\n",
    "ae3.fit(train, train, epochs=100, batch_size=32, validation_data=(val, val),callbacks=check(3), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression of Images With Conventional Methods For Each Quality Chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base directory for compressed images\n",
    "base_output_dir = 'C:/Users/GOKAY/Desktop/compressed_images/conv/'\n",
    "\n",
    "#Subdirectories to be created for each combination (except tiff)\n",
    "formats = ['JPEG', 'WEBP', 'TIFF']\n",
    "qualities = [25, 50, 75]\n",
    "\n",
    "#Checking if already bases directory exists\n",
    "if not os.path.exists(base_output_dir):\n",
    "    os.makedirs(base_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating subdirectories\n",
    "for formt in formats:\n",
    "    #Creating subdirectories for jpeg and webp\n",
    "    if formt != 'TIFF':\n",
    "        for quality in qualities:\n",
    "            dir_path = os.path.join(base_output_dir, f'{formt} {quality}')\n",
    "            if not os.path.exists(dir_path):\n",
    "                os.makedirs(dir_path)\n",
    "    else:\n",
    "        #Subdirectory for tiff\n",
    "        dir_path = os.path.join(base_output_dir, formt)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing each image file in the test set \n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.lower().endswith(('.jpg')): \n",
    "        img_path = os.path.join(test_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        #Comperssing and saving the image in each format and quality setting\n",
    "        for formt in formats:\n",
    "            base_filename = filename.rsplit('.', 1)[0]  # Strip extension\n",
    "            #jpeg and webp compressions\n",
    "            if formt != 'TIFF':\n",
    "                for quality in qualities:\n",
    "                    output_filename = f\"{base_filename}.{formt.lower()}\"\n",
    "                    output_filepath = os.path.join(base_output_dir, f'{formt} {quality}', output_filename)\n",
    "                    img.save(output_filepath, format=formt, quality=quality)\n",
    "            #tiff compression\n",
    "            else:\n",
    "                output_filename = f\"{base_filename}.{formt.lower()}\"\n",
    "                output_filepath = os.path.join(base_output_dir, formt, output_filename)\n",
    "                img.save(output_filepath, format=formt, compression='tiff_lzw')\n",
    "\n",
    "print(\"Image compression was done successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
