{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GOKAY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#libraries for building the autoencoder\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#metric libraries\n",
    "import time\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.color import rgb2gray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing The Image Directories and Looking For Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access image directories\n",
    "train_dir = 'C:/Users/GOKAY/Desktop/imagenette4/train/'\n",
    "val_dir = 'C:/Users/GOKAY/Desktop/imagenette4/val/'\n",
    "test_dir = 'C:/Users/GOKAY/Desktop/imagenette4/test/'\n",
    "\n",
    "#train set\n",
    "train = []\n",
    "for filename in os.listdir(train_dir):\n",
    "    if filename.endswith(\".JPEG\"):\n",
    "        img = image.load_img(train_dir+filename, target_size=(160, 160))\n",
    "        train.append(image.img_to_array(img))\n",
    "train = np.array(train)\n",
    "\n",
    "#validation set\n",
    "val = []\n",
    "for filename in os.listdir(val_dir):\n",
    "    if filename.endswith(\".JPEG\"):\n",
    "        img = image.load_img(val_dir+filename, target_size=(160, 160))\n",
    "        val.append(image.img_to_array(img))\n",
    "val = np.array(val)\n",
    "\n",
    "#test set\n",
    "test = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith(\".JPEG\"):\n",
    "        img = image.load_img(test_dir+filename, target_size=(160, 160))\n",
    "        test.append(image.img_to_array(img))\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (9469, 160, 160, 3)\n",
      "val (1961, 160, 160, 3)\n",
      "test (1964, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train\", train.shape)\n",
    "print(\"val\", val.shape)\n",
    "print(\"test\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a Function For Model Creation (Which Is Changed For Each Architecture Manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    #hypermeters to be found\n",
    "    num_filters1 = trial.suggest_categorical('num_filters1', [32])\n",
    "    num_filters2 = trial.suggest_categorical('num_filters2', [32,64])\n",
    "    num_filters3 = trial.suggest_categorical('num_filters3', [32, 64, 128])\n",
    "    activation = trial.suggest_categorical('activation', ['relu','leaky_relu'])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "\n",
    "    #encoder\n",
    "    input_layer = Input(shape=(160,160,3), name='INPUT')\n",
    "    #first layer\n",
    "    x = Conv2D(num_filters1, (3, 3), activation=activation, padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    #second layer\n",
    "    x = Conv2D(num_filters2, (3, 3), activation=activation, padding='same' )(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    #third layer\n",
    "    x = Conv2D(num_filters3, (3, 3), activation=activation, padding='same')(x)\n",
    "\n",
    "    latent_layer = MaxPooling2D((2, 2), name='CODE')(x)\n",
    "\n",
    "    #decoder\n",
    "    #fourth layer\n",
    "    x = Conv2DTranspose(num_filters3, (3, 3), activation=activation, padding='same')(latent_layer)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    #fifth layer\n",
    "    x = Conv2DTranspose(num_filters2, (3, 3), activation=activation, padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    #sixth layer\n",
    "    x = Conv2DTranspose(num_filters1, (3, 3), activation=activation, padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    output_layer = Conv2D(3, (3, 3), padding='same', name=\"OUTPUT\")(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    #autoencoder.summary()\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a Objective Function For Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #creating the model and setting up the parameters for testing.\n",
    "    model = create_model(trial)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train, train, epochs=15, batch_size=32, validation_data=(val, val), callbacks=[early_stopping], verbose=1)\n",
    "    time_taken = time.time()-start_time\n",
    "\n",
    "    #prediction on val set\n",
    "    val_pred = model.predict(val)\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "\n",
    "    for i in range(len(val)):\n",
    "        #creating a new set of the same images which turned into gray scale for SSIM test. RGB images are problematic.\n",
    "        val_gray = rgb2gray(val[i])\n",
    "        val_pred_gray = rgb2gray(val_pred[i])\n",
    "\n",
    "        #holding the scores of metrics\n",
    "        ssim_score = ssim(val_gray, val_pred_gray, data_range=val_pred_gray.max() - val_pred_gray.min())\n",
    "        psnr_score = psnr(val[i], val_pred[i], data_range=val_pred[i].max() - val_pred[i].min())\n",
    "        ssim_scores.append(ssim_score)\n",
    "        psnr_scores.append(psnr_score)\n",
    "    \n",
    "    #mean values of metrics and combined score. Optuna finds the minimum value. Therefore, combined score's sign is changed to minus in order to get the actual highest value.\n",
    "    mean_ssim = np.mean(ssim_scores)\n",
    "    mean_psnr = np.mean(psnr_scores)\n",
    "    combined_score = -1 * (mean_ssim + mean_psnr)\n",
    "\n",
    "    #attributes are set to receive them later on.\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    epochs_taken = len(history.history['val_loss'])\n",
    "    trial.set_user_attr('epochs', epochs_taken)\n",
    "    trial.set_user_attr('SSIM', mean_ssim)\n",
    "    trial.set_user_attr('PSNR', mean_psnr)\n",
    "    trial.set_user_attr('combined_score', combined_score)\n",
    "    trial.set_user_attr('final_val_loss', val_loss)\n",
    "    trial.set_user_attr(\"time_taken\", time_taken)\n",
    "\n",
    "    #combined score is returned, optuna watches for the returned variable in the objective function\n",
    "    return combined_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying the Hypermeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding The Best Trial and Its Hypermeters, According to the Combined Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print('Best hyperparameters for combined score:', best_trial.params)\n",
    "print(\"Best SSIM:\", best_trial.user_attrs['SSIM'])\n",
    "print(\"Best PSNR:\", best_trial.user_attrs['PSNR'])\n",
    "print(\"Best Combined Score:\",best_trial.user_attrs['combined_score'])\n",
    "print('Number of epochs:', best_trial.user_attrs['epochs'])\n",
    "print('Final validation loss:', best_trial.user_attrs['final_val_loss'])\n",
    "print('Time taken for the best result: ', best_trial.user_attrs['time_taken'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
